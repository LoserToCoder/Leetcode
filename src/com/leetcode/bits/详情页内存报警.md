<h1><center>内存报警排查</center></h1>

## 1 问题

​	详情页内存报警，内存使用率达到85%以上。

## 2 排查思路

### 2.1 查看Medus监控

<img src="https://image1.guazistatic.com/qn21120211373523cacf4dca22459ffe3b38dfd821578a.png">

<center style="color: #acabbe;font-size: 14px;" name="1_1">1.1 Medusa服务监控看板图</center>

可点击more查看grafana看板，查看更长时间的内存变化曲线，通过观察变化曲线，再去查看日志，某个时间段发生了什么，可能会对服务造成什么影响



当时detail的大概情况（当时未截图，曲线是如此，但是纵轴比现在高）

<img src="https://image1.guazistatic.com/qn2112021137398343c593e74ffd96f3e757ab68b8fb45.png">

<center style="color: #acabbe;font-size: 14px;">1.2 grafana内存监控看板</center>

通过曲线基本平稳分析不出来有什么问题

### 2.2 dump内存

#### 2.2.1 进入容器

选择自己需要查看的部署，并点击进入

<img src="https://image1.guazistatic.com/qn21120211510925cae7e0c382e2048788dd3058c68ad9.png">

<center style="color: #acabbe;font-size: 14px;">2.1 Medusa部署实例图</center>

先将节点展开，选择上一章节查看的内存异常的节点名称，点击终端进入

<img src="https://image1.guazistatic.com/qn211202115238c9b698fb116d116ff5b744fcecd470b9.png">

<center style="color: #acabbe;font-size: 14px;">2.2 Medusa节点图</center>

#### 2.2.2 命令

```shell
jps（查看当前系统所有java应用，取pid）
```

```shell
jmap -dump:format=b,file=detail.hprof pid（dump一份内存）
```

```shell
scp ./detail.hprof baiyongxiao@10.115.120.46:/Users/baiyongxiao/util/heap/detail.hprof（将文件拷贝到本地）
```

<img src="https://image1.guazistatic.com/qn211202115853c9d9193ba1ea98d9443e62f5ad72a9f6.png">

<center style="color: #acabbe;font-size: 14px;" name="2_3">2.3 JProfiler内存快照分析图</center>

```
jstat -gc 2000 10 1（监控内存回收情况，2000：间隔2000毫秒打印一条记录，10:累计打印10次终止，1:pid）	
```

<img src="https://image1.guazistatic.com/qn211202120330631888b766656a7ebd54a3c873f3bfa1.png">

<center style="color: #acabbe;font-size: 14px;" name="2_4">2.4 GC垃圾回收图</center>	

<a href="https://blog.csdn.net/qq_36628536/article/details/109071799">参数详解</a>

#### 2.2.3 分析

​	根据[2.3 JProfiler内存快照分析图](#2_3)可以看出当前内存快照中的内容并未有非常大的内存占用

​	根据[2.4 GC垃圾回收图](#2_4)可以看出当前节点内存回收情况依旧正常，未存在不可回收的垃圾

​	到此可以得出结论，该次系统内存报警，堆内存一切正常，基本可以排除堆内存，因此接下来的排查方向应该是堆外内存

### 2.3 JVM堆外内存

#### 2.3.1 JVM参数之NativeMemoryTracking

​	Java8给HotSpot VM引入了Native Memory Tracking (NMT)特性，可以用于追踪JVM的内部内存使用，一般在压测调参或者排查问题的时候使用，生产环境不要引入，因为会造成5%-10%的性能损耗。		

​	在java启动命令加入参数：-XX:NativeMemoryTracking=[off | summary | detail] 

​	我使用的是==summary==，因为只需要统计一下各模块总量的变化

```shell
jcmd <pid> VM.native_memory [summary | detail | baseline | summary.diff | detail.diff | shutdown] [scale= KB | MB | GB]]

//我使用的是如下命令（如图2.5所示）
jcmd 1 VM.native_memory baseline
//过一段时间之后又使用了（该处当时未截图，但是总体内存占用并没有什么增量）
jcmd 1 VM.native_memory summary.diff
```

<img src="https://image1.guazistatic.com/qn211203154848aec23b974697e3ad0bdb57c31ad088ac.png" style="width: 80%;heigth: 40%">

<center style="color: #acabbe;font-size: 14px;" name="2_6">2.6 当前的JVM内存分布</center>	

### 2.4 日志分析

​	在上述内存的分析中并未得到结论，因此就将目标转到了日志上，看日志中是否有什么变化，能够影响到此处。

​	经过查询日志，以及报警的时间，发现有一个==在线化的AB实验==在内存报警的前两天过期了，但是由于次实验调用量非常大，导致每日平均增加了几十万（记忆中是）的堆栈日志，因此考虑是否是因为堆栈日志过多导致来不及全部写入文件，随着时间增加一点一点堆积在内存中，导致超过了85%。

​	经过修改调整上线，过了两天发现还是一直有报警，内存还是不断上涨，因此不是该处导致的。

### 2.5 程序内存分析

​	查看当前应用所有的内存大小分布

```shell
//‘1‘是pid
cat /proc/1/maps
//可将其输出到文件中传输到本机进行分析
cat /proc/1/maps > maps.txt
scp ./maps.txt baiyongxiao@10.115.120.46:/Users/baiyongxiao/util/heap/maps.txt（将文件拷贝到本地）
```

​	将内存块按照大小排序，挑选比较大的内存，然后记住其内存地址，在上一步全部内存块分布中查找该内存块，并记录下起始和终止地址（后续需要查看内容使用）

```
pmap -x pid | sort -n -k3
```

​	该处需要给容器安装脚本程序：==GDB==

```shell
yum install gdb
```

​	dump这一块内存地址中间的内容

```
gdb --batch --pid $pid -ex "dump memory a.dump 0x7fa624000000 0x7fa625435000"
```

​	查看其中的内容

```
//strings -10 a.dump 可使用该命令查看大于10字符的内容，因为太小的参考意义不大
strings a.dump
```

​	重复上述操作，将可疑的内存都排查了一遍，发现并未有可疑的情况

### 2.6 调用栈分析

​	主要分析CPU在做什么，对内存的分析有时候会有帮助，上面排查日志修复异常堆栈主要原因也有分析该处的原因。

​	需要安装perf工具	

```shell
yum -g install perf
```

​	进行监控, 大概执行几分钟按CRTL+C，会在当前目录生成perf.data文件

```shell
perf record -m 2 -g -p pid
```

​	对perf.data进行分析

```shell
perf report -i perf.data
```

<img src="https://image1.guazistatic.com/qn21120818215670c47ea557bf99c8c4443a8df74b879e.png"></img>

<center style="color: #acabbe;font-size: 14px;" name="2_7">2.7 CPU栈函数调用分析图</center>	

### 2.7 内存分配

​	通过上述分析，基本排除了程序导致的内存异常，因此开始查看是否内存分配的太大，然后对启动命令参数进行了调整。

​	原命令

```shell
java -Dspring.profiles.active=$MED_ENV -XX:InitialRAMPercentage=65.0 -XX:MaxRAMPercentage=65.0 -Xss256k -XX:+UseG1GC -XX:+PrintGC -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:HeapDumpPath=/med/share/ -XX:-UseAdaptiveSizePolicy  -Dfile.encoding=UTF-8 -jar ./target/mall-bff-detail-1.0-SNAPSHOT.war
```

​	现命令

```shell
java -Dspring.profiles.active=$MED_ENV -XX:InitialRAMPercentage=60.0 -XX:MaxRAMPercentage=60.0 -Xss256k -XX:+UseG1GC -XX:+PrintGC -XX:+HeapDumpOnOutOfMemoryError -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:HeapDumpPath=/med/share/ -XX:-UseAdaptiveSizePolicy  -Dfile.encoding=UTF-8 -jar ./target/mall-bff-detail-1.0-SNAPSHOT.war
```

​	上述调整了==-XX:InitialRAMPercentage==参数，将初始内存占比下调5%，然后观察几天内存变化，发现内存占用最高点基本稳定在80%左右。

## 3 总结

​	该次报警应该是一直存在的，只是日常工作中大家上线过于频繁，涨到85%需要3天左右的时间，因此在十月一期间才会报警。以上使用的工具、命令、参数等，如果想深入了解可自行百度学习，网上均有详细的介绍。
